"""æ‰§è¡Œå¼•æ“ â€” ä»»åŠ¡è°ƒåº¦ã€å‘˜å·¥æ‰§è¡Œã€å·¥å…·è·¯ç”±ã€ä¼šè®®ç¼–æ’."""

from __future__ import annotations

import asyncio
import logging
import json
import uuid
from pathlib import Path
from typing import Any

logger = logging.getLogger(__name__)

from crew.exceptions import EmployeeNotFoundError, PipelineNotFoundError
from crew.webhook_context import _AppContext, _MAX_TOOL_ROUNDS
from crew.webhook_tools import get_all_tool_handlers

_TOOL_HANDLERS: dict[str, Any] = get_all_tool_handlers()


async def _dispatch_task(
    ctx: _AppContext,
    trigger: str,
    target_type: str,
    target_name: str,
    args: dict[str, str],
    sync: bool = False,
    agent_id: int | None = None,
    model: str | None = None,
) -> Any:
    """åˆ›å»ºä»»åŠ¡å¹¶è°ƒåº¦æ‰§è¡Œ."""
    from starlette.responses import JSONResponse

    trace_id = uuid.uuid4().hex[:12]
    record = ctx.registry.create(
        trigger=trigger,
        target_type=target_type,
        target_name=target_name,
        args=args,
    )
    logger.info(
        "ä»»åŠ¡å¼€å§‹ [trace=%s] %s â†’ %s/%s (task=%s)",
        trace_id, trigger, target_type, target_name, record.task_id,
    )

    # é€šè¿‡ webhook æ¨¡å—æŸ¥æ‰¾ï¼Œç¡®ä¿ mock patch ç”Ÿæ•ˆ
    import crew.webhook as _wh

    if sync:
        await _wh._execute_task(ctx, record.task_id, agent_id=agent_id, model=model, trace_id=trace_id)
        record = ctx.registry.get(record.task_id)
        return JSONResponse(record.model_dump(mode="json"))

    asyncio.create_task(_wh._execute_task(ctx, record.task_id, agent_id=agent_id, model=model, trace_id=trace_id))
    return JSONResponse(
        {"task_id": record.task_id, "status": "pending"},
        status_code=202,
    )


async def _execute_task(
    ctx: _AppContext,
    task_id: str,
    agent_id: int | None = None,
    model: str | None = None,
    trace_id: str = "",
) -> None:
    """æ‰§è¡Œä»»åŠ¡."""
    record = ctx.registry.get(task_id)
    if record is None:
        return

    ctx.registry.update(task_id, "running")

    # é€šè¿‡ webhook æ¨¡å—æŸ¥æ‰¾ï¼Œç¡®ä¿ mock patch ç”Ÿæ•ˆ
    import crew.webhook as _wh

    try:
        if record.target_type == "pipeline":
            logger.info("æ‰§è¡Œ pipeline [trace=%s] %s", trace_id, record.target_name)
            result = await _wh._execute_pipeline(
                ctx, record.target_name, record.args, agent_id=agent_id, task_id=task_id,
            )
        elif record.target_type == "employee":
            logger.info("æ‰§è¡Œ employee [trace=%s] %s", trace_id, record.target_name)
            result = await _wh._execute_employee(
                ctx, record.target_name, record.args, agent_id=agent_id, model=model,
            )
        elif record.target_type == "meeting":
            logger.info("æ‰§è¡Œ meeting [trace=%s] %s", trace_id, record.target_name)
            employees = [e.strip() for e in record.args.get("employees", "").split(",") if e.strip()]
            result = await _wh._execute_meeting(
                ctx,
                task_id=task_id,
                employees=employees,
                topic=record.args.get("topic", ""),
                goal=record.args.get("goal", ""),
                rounds=int(record.args.get("rounds", "2")),
            )
        elif record.target_type == "chain":
            logger.info("æ‰§è¡Œ chain [trace=%s] %s", trace_id, record.target_name)
            import json as _json

            steps = _json.loads(record.args.get("steps_json", "[]"))
            result = await _wh._execute_chain(ctx, task_id, steps)
        else:
            ctx.registry.update(task_id, "failed", error=f"æœªçŸ¥ç›®æ ‡ç±»å‹: {record.target_type}")
            return

        # æˆæœ¬è¿½è¸ªï¼šå‘ç»“æœè¿½åŠ  cost_usd
        if isinstance(result, dict):
            try:
                from crew.cost import enrich_result_with_cost
                enrich_result_with_cost(result)
            except Exception as e:
                logger.debug("æˆæœ¬è¿½è¸ªå¤±è´¥: %s", e)

        logger.info("ä»»åŠ¡å®Œæˆ [trace=%s] task=%s", trace_id, task_id)
        ctx.registry.update(task_id, "completed", result=result)

        # B ç±»æƒé™æ ‡è®° + è´¨é‡è¯„åˆ† + è‡ªåŠ¨é™çº§æ£€æŸ¥
        if record.target_type == "employee" and isinstance(result, dict):
            try:
                from crew.organization import load_organization, record_task_outcome

                org = load_organization(project_dir=ctx.project_dir)
                auth = org.get_authority(record.target_name)
                if auth == "B":
                    result["needs_kai_approval"] = True
                    result["authority_note"] = (
                        "æ­¤å‘˜å·¥ä¸º B ç±»ï¼ˆéœ€ Kai ç¡®è®¤ï¼‰ï¼Œ"
                        "ç»“æœä»…ä¾›å‚è€ƒï¼Œè¯· Kai è¿‡ç›®åå†å†³å®šä¸‹ä¸€æ­¥ã€‚"
                    )

                # è´¨é‡è¯„åˆ†è§£æ
                output_text = result.get("output", "")
                if output_text:
                    from crew.cost import parse_quality_score
                    qscore = parse_quality_score(output_text)
                    if qscore:
                        result["quality_score"] = qscore

                # è‡ªåŠ¨è®°å¿†ä¿å­˜ï¼ˆopt-inï¼‰+ è‡ªæ£€æå–ï¼ˆç‹¬ç«‹äº auto_memoryï¼‰
                if output_text and len(output_text) > 50:
                    try:
                        from crew.discovery import discover_employees
                        disc = discover_employees(project_dir=ctx.project_dir)
                        match = disc.get(record.target_name)
                        task_desc = record.args.get("task", "")[:100]
                        _mem_store = None

                        if match and getattr(match, "auto_memory", False):
                            from crew.memory import MemoryStore
                            _mem_store = MemoryStore(project_dir=ctx.project_dir)
                            summary = output_text[:300].strip()
                            if len(output_text) > 300:
                                summary += "..."
                            _mem_store.add(
                                employee=record.target_name,
                                category="finding",
                                content=f"[ä»»åŠ¡] {task_desc} â†’ {summary}",
                                source_session=record.task_id if hasattr(record, "task_id") else task_id,
                                confidence=0.6,
                                ttl_days=30,
                            )
                            logger.info("è‡ªåŠ¨è®°å¿†ä¿å­˜: %s", record.target_name)

                        # è‡ªæ£€æ‘˜è¦æå– â€” ç‹¬ç«‹äº auto_memoryï¼Œæœ‰è‡ªæ£€æ®µå°±æå–
                        import re as _re
                        check_match = _re.search(
                            r"##\s*å®Œæˆåè‡ªæ£€[^\n]*\n+((?:- \[.\].*\n?)+)",
                            output_text,
                        )
                        if check_match:
                            if _mem_store is None:
                                from crew.memory import MemoryStore
                                _mem_store = MemoryStore(project_dir=ctx.project_dir)
                            check_lines = check_match.group(1).strip().split("\n")
                            passed = []
                            failed = []
                            for cl in check_lines:
                                cl = cl.strip()
                                if cl.startswith("- [x]") or cl.startswith("- [X]"):
                                    passed.append(cl[5:].strip())
                                elif cl.startswith("- [ ]"):
                                    failed.append(cl[5:].strip())
                            parts = [f"[è‡ªæ£€] {task_desc}"]
                            if passed:
                                parts.append(f"é€šè¿‡: {'; '.join(passed)}")
                            if failed:
                                parts.append(f"å¾…æ”¹è¿›: {'; '.join(failed)}")
                            _mem_store.add(
                                employee=record.target_name,
                                category="correction",
                                content=" | ".join(parts),
                                source_session=record.task_id if hasattr(record, "task_id") else task_id,
                                confidence=0.7,
                                ttl_days=60,
                                shared=True,
                            )
                            logger.info("è‡ªæ£€æ‘˜è¦ä¿å­˜: %s", record.target_name)
                    except Exception as e_mem:
                        logger.debug("è‡ªåŠ¨è®°å¿†/è‡ªæ£€ä¿å­˜å¤±è´¥: %s", e_mem)

                # è‡ªåŠ¨é™çº§æ£€æŸ¥ï¼ˆè®°å½•æˆåŠŸï¼‰
                record_task_outcome(
                    record.target_name, success=True,
                    project_dir=ctx.project_dir,
                )
            except Exception as e:
                logger.warning("ä»»åŠ¡åå¤„ç†å¤±è´¥ (employee=%s): %s", record.target_name, e)
    except Exception as e:
        logger.exception("ä»»åŠ¡æ‰§è¡Œå¤±è´¥ [trace=%s]: %s", trace_id, task_id)
        ctx.registry.update(task_id, "failed", error=str(e))
        # è‡ªåŠ¨é™çº§æ£€æŸ¥ï¼ˆè®°å½•å¤±è´¥ï¼‰
        if record.target_type == "employee":
            try:
                from crew.organization import record_task_outcome
                record_task_outcome(
                    record.target_name, success=False,
                    project_dir=ctx.project_dir,
                )
            except Exception:
                pass


async def _execute_pipeline(
    ctx: _AppContext,
    name: str,
    args: dict[str, str],
    agent_id: int | None = None,
    task_id: str | None = None,
) -> dict[str, Any]:
    """æ‰§è¡Œ pipeline."""
    from crew.pipeline import arun_pipeline, discover_pipelines, load_pipeline

    pipelines = discover_pipelines(project_dir=ctx.project_dir)
    if name not in pipelines:
        raise PipelineNotFoundError(name)

    pipeline = load_pipeline(pipelines[name])

    # æ„å»º checkpoint å›è°ƒ
    on_step_complete = None
    if task_id:
        def on_step_complete(step_result, checkpoint_data):
            ctx.registry.update_checkpoint(task_id, checkpoint_data)

    result = await arun_pipeline(
        pipeline,
        initial_args=args,
        project_dir=ctx.project_dir,
        execute=True,
        api_key=None,
        agent_id=agent_id,
        on_step_complete=on_step_complete,
    )
    return result.model_dump(mode="json")


async def _delegate_employee(
    ctx: _AppContext,
    employee_name: str,
    task: str,
    *,
    model: str | None = None,
) -> str:
    """æ‰§è¡Œè¢«å§”æ´¾çš„å‘˜å·¥ï¼ˆçº¯æ–‡æœ¬è¾“å…¥/è¾“å‡ºï¼Œä¸æ”¯æŒé€’å½’å§”æ´¾ï¼‰."""
    from crew.discovery import discover_employees
    from crew.engine import CrewEngine

    discovery = discover_employees(project_dir=ctx.project_dir)
    target = discovery.get(employee_name)
    if target is None:
        available = ", ".join(sorted(discovery.employees.keys()))
        return f"é”™è¯¯ï¼šæœªæ‰¾åˆ°å‘˜å·¥ '{employee_name}'ã€‚å¯ç”¨å‘˜å·¥ï¼š{available}"

    engine = CrewEngine(project_dir=ctx.project_dir)
    prompt = engine.prompt(target, args={"task": task})

    try:
        from crew.executor import aexecute_prompt

        use_model = target.model or model or "claude-sonnet-4-20250514"
        result = await aexecute_prompt(
            system_prompt=prompt,
            user_message=task,
            api_key=None,
            model=use_model,
            stream=False,
        )
        return result.content
    except Exception as e:
        return f"å§”æ´¾æ‰§è¡Œå¤±è´¥: {e}"


async def _execute_meeting(
    ctx: _AppContext,
    task_id: str,
    employees: list[str],
    topic: str,
    goal: str = "",
    rounds: int = 2,
) -> dict[str, Any]:
    """æ‰§è¡Œå¤šå‘˜å·¥ä¼šè®®ï¼ˆç¼–æ’å¼è®¨è®ºï¼‰â€” æ¯è½®å‚ä¼šè€…å¹¶è¡Œ."""
    from crew.discussion import create_adhoc_discussion, render_discussion_plan
    from crew.executor import aexecute_prompt

    discussion = create_adhoc_discussion(
        employees=employees, topic=topic, goal=goal, rounds=rounds,
    )
    plan = render_discussion_plan(
        discussion, initial_args={}, project_dir=ctx.project_dir, smart_context=True,
    )

    all_rounds: list[dict[str, Any]] = []
    previous_rounds_text = ""

    for rp in plan.rounds:
        logger.info(
            "ä¼šè®® %s ç¬¬ %d è½® '%s' (%d äºº)",
            task_id, rp.round_number, rp.name, len(rp.participant_prompts),
        )

        # æ›¿æ¢ {previous_rounds} å¹¶å¹¶è¡Œæ‰§è¡Œ
        coros = []
        names = []
        for pp in rp.participant_prompts:
            prompt_text = pp.prompt.replace("{previous_rounds}", previous_rounds_text)
            coros.append(aexecute_prompt(
                system_prompt=prompt_text,
                user_message="è¯·å¼€å§‹ã€‚",
                api_key=None,
                model="claude-sonnet-4-20250514",
                stream=False,
            ))
            names.append(pp.employee_name)

        results = await asyncio.gather(*coros, return_exceptions=True)

        round_outputs = []
        for i, out in enumerate(results):
            content = f"[æ‰§è¡Œå¤±è´¥: {out}]" if isinstance(out, Exception) else out.content
            round_outputs.append({"employee": names[i], "content": content})

        all_rounds.append({
            "round_num": rp.round_number,
            "name": rp.name,
            "outputs": round_outputs,
        })

        # ç§¯ç´¯ä¸Šä¸‹æ–‡
        parts = [f"**{o['employee']}**: {o['content']}" for o in round_outputs]
        previous_rounds_text += f"\n\n## ç¬¬ {rp.round_number} è½®: {rp.name}\n" + "\n\n".join(parts)

    # ç»¼åˆç»“è®º
    synthesis_prompt = plan.synthesis_prompt.replace("{previous_rounds}", previous_rounds_text)
    synthesis = await aexecute_prompt(
        system_prompt=synthesis_prompt,
        user_message="è¯·ç»¼åˆä»¥ä¸Šè®¨è®ºï¼Œç»™å‡ºæœ€ç»ˆç»“è®ºã€‚",
        api_key=None,
        model="claude-sonnet-4-20250514",
        stream=False,
    )

    return {
        "rounds": all_rounds,
        "synthesis": synthesis.content,
    }


async def _execute_chain(
    ctx: _AppContext,
    task_id: str,
    steps: list[dict[str, str]],
    *,
    start_index: int = 0,
    prev_output: str = "",
    step_results: list[dict[str, str]] | None = None,
) -> dict[str, Any]:
    """æŒ‰é¡ºåºæ‰§è¡Œå§”æ´¾é“¾ï¼Œå‰ä¸€æ­¥ç»“æœä¼ ç»™ä¸‹ä¸€æ­¥.

    æ”¯æŒå®¡æ‰¹æ£€æŸ¥ç‚¹: é‡åˆ° approval æ­¥éª¤æ—¶æš‚åœé“¾æ‰§è¡Œï¼Œä¿å­˜æ–­ç‚¹ï¼Œ
    é€šçŸ¥ Kai å®¡æ‰¹ã€‚æ‰¹å‡†åé€šè¿‡ _resume_chain ä»æ–­ç‚¹æ¢å¤ã€‚
    """
    from crew.discovery import discover_employees
    from crew.engine import CrewEngine
    from crew.executor import aexecute_prompt

    discovery = discover_employees(project_dir=ctx.project_dir)
    engine = CrewEngine(project_dir=ctx.project_dir)

    if step_results is None:
        step_results = []

    for i in range(start_index, len(steps)):
        step = steps[i]
        emp_name = step["employee_name"]

        # å®¡æ‰¹æ£€æŸ¥ç‚¹: æš‚åœé“¾æ‰§è¡Œ
        if step.get("approval") and i > start_index:
            checkpoint = {
                "chain_step": i,
                "steps_json": json.dumps(steps, ensure_ascii=False),
                "prev_output": prev_output,
                "step_results": step_results,
            }
            ctx.registry.update_checkpoint(task_id, checkpoint)
            ctx.registry.update(task_id, "awaiting_approval")
            await _notify_approval_needed(ctx, task_id, step, prev_output)
            return {
                "steps": step_results,
                "status": "awaiting_approval",
                "pending_step": emp_name,
                "message": f"æ­¥éª¤ {i + 1} ({emp_name}) éœ€è¦å®¡æ‰¹ï¼Œå·²é€šçŸ¥ Kai",
            }

        task_desc = step["task"].replace("{prev}", prev_output)

        target = discovery.get(emp_name)
        if target is None:
            step_results.append({"employee": emp_name, "error": f"æœªæ‰¾åˆ°å‘˜å·¥ '{emp_name}'"})
            break

        logger.info("Chain %s æ­¥éª¤ %d/%d: %s", task_id, i + 1, len(steps), emp_name)
        prompt = engine.prompt(target, args={"task": task_desc})
        use_model = target.model or "claude-sonnet-4-20250514"

        try:
            result = await aexecute_prompt(
                system_prompt=prompt,
                user_message=task_desc,
                api_key=None,
                model=use_model,
                stream=False,
            )
            prev_output = result.content
            step_results.append({"employee": emp_name, "content": result.content})
        except Exception as e:
            step_results.append({"employee": emp_name, "error": str(e)})
            break

    return {"steps": step_results, "final_output": prev_output}


async def _notify_approval_needed(
    ctx: _AppContext, task_id: str, step: dict, prev_output: str,
) -> None:
    """é€šè¿‡é£ä¹¦ç§èŠé€šçŸ¥ Kai æœ‰æ­¥éª¤ç­‰å¾…å®¡æ‰¹."""
    if not (ctx.feishu_token_mgr and ctx.feishu_config):
        logger.info("å®¡æ‰¹é€šçŸ¥è·³è¿‡: é£ä¹¦æœªé…ç½® (task=%s)", task_id)
        return
    owner_id = ctx.feishu_config.owner_open_id
    if not owner_id:
        logger.info("å®¡æ‰¹é€šçŸ¥è·³è¿‡: owner_open_id æœªé…ç½® (task=%s)", task_id)
        return

    emp_name = step.get("employee_name", "?")
    task_text = step.get("task", "")
    role = task_text.split("]")[0].lstrip("[") if "]" in task_text else emp_name
    summary = prev_output[:300] if prev_output else "ï¼ˆæ— å‰åºè¾“å‡ºï¼‰"

    text = (
        f"ğŸ“‹ ä»»åŠ¡ {task_id} ç­‰å¾…å®¡æ‰¹\n\n"
        f"ä¸‹ä¸€æ­¥: {emp_name}ï¼ˆ{role}ï¼‰\n"
        f"å‰åºç»“æœæ‘˜è¦:\n{summary}\n\n"
        f"å›å¤ã€Œapprove {task_id}ã€æ‰¹å‡†\n"
        f"å›å¤ã€Œreject {task_id}ã€æ‹’ç»"
    )

    try:
        from crew.feishu import send_feishu_message
        await send_feishu_message(
            ctx.feishu_token_mgr, owner_id, {"text": text}, msg_type="text",
        )
    except Exception as e:
        logger.warning("å®¡æ‰¹é€šçŸ¥å‘é€å¤±è´¥ (task=%s): %s", task_id, e)


async def _resume_chain(ctx: _AppContext, task_id: str) -> None:
    """ä»å®¡æ‰¹æ£€æŸ¥ç‚¹æ¢å¤é“¾æ‰§è¡Œ."""
    record = ctx.registry.get(task_id)
    if not record or record.status != "awaiting_approval":
        return
    if not record.checkpoint:
        ctx.registry.update(task_id, "failed", error="æ— æ–­ç‚¹æ•°æ®")
        return

    cp = record.checkpoint
    steps = json.loads(cp["steps_json"])
    start_index = cp["chain_step"]
    prev_output = cp["prev_output"]
    step_results = cp.get("step_results", [])

    ctx.registry.update(task_id, "running")

    try:
        result = await _execute_chain(
            ctx, task_id, steps,
            start_index=start_index,
            prev_output=prev_output,
            step_results=step_results,
        )
        # å¦‚æœåˆé‡åˆ°å®¡æ‰¹æ£€æŸ¥ç‚¹ï¼Œ_execute_chain å·²å¤„ç†ï¼Œä¸éœ€è¦å† update
        if result.get("status") == "awaiting_approval":
            return
        ctx.registry.update(task_id, "completed", result=result)
    except Exception as e:
        logger.exception("æ¢å¤é“¾æ‰§è¡Œå¤±è´¥ [task=%s]: %s", task_id, e)
        ctx.registry.update(task_id, "failed", error=str(e))


async def _execute_employee_with_tools(
    ctx: _AppContext,
    name: str,
    args: dict[str, str],
    *,
    agent_id: int | None = None,
    model: str | None = None,
    user_message: "str | list[dict[str, Any]] | None" = None,
    message_history: list[dict[str, Any]] | None = None,
) -> dict[str, Any]:
    """æ‰§è¡Œå¸¦å·¥å…·çš„å‘˜å·¥ï¼ˆagent loop with toolsï¼‰."""
    from crew.discovery import discover_employees
    from crew.engine import CrewEngine
    from crew.executor import aexecute_with_tools
    from crew.providers import Provider, detect_provider
    from crew.tool_schema import (
        AGENT_TOOLS, employee_tools_to_schemas,
        get_tool_schema, is_finish_tool, _make_load_tools_schema,
    )

    discovery = discover_employees(project_dir=ctx.project_dir)
    match = discovery.get(name)
    if match is None:
        raise EmployeeNotFoundError(name)

    # agent èº«ä»½
    agent_identity = None
    if agent_id:
        try:
            from crew.id_client import afetch_agent_identity
            agent_identity = await afetch_agent_identity(agent_id)
        except Exception as e:
            logger.debug("agent èº«ä»½è·å–å¤±è´¥ (agent_id=%s): %s", agent_id, e)

    engine = CrewEngine(project_dir=ctx.project_dir)
    # ä» args ä¸­æå– _max_visibilityï¼ˆé£ä¹¦ dispatch ä¼ å…¥ï¼‰
    max_visibility = args.pop("_max_visibility", "open") if isinstance(args, dict) else "open"
    prompt = engine.prompt(match, args=args, agent_identity=agent_identity, max_visibility=max_visibility)

    # å¦‚æœæœ‰ delegate å·¥å…·ï¼Œè¿½åŠ åŒäº‹åå•ï¼ˆæŒ‰ç»„ç»‡æ¶æ„åˆ†ç»„ï¼‰
    if "delegate" in (match.tools or []):
        from crew.organization import load_organization, get_effective_authority

        org = load_organization(project_dir=ctx.project_dir)

        # ç´§å‡‘åå•æ ¼å¼ â€” çœæ‰æè¿°ï¼ˆemployee name å·²è‡ªæè¿°ï¼‰ï¼Œæ¯ç»„ä¸€è¡Œ
        team_members: dict[str, list[str]] = {}
        ungrouped: list[str] = []

        for emp_name, emp in discovery.employees.items():
            if emp_name == name:
                continue
            label = emp.character_name or emp.effective_display_name
            auth = get_effective_authority(org, emp_name, project_dir=ctx.project_dir) or "?"
            tag = f"{emp_name}({label},{auth})"
            team_id = org.get_team(emp_name)
            if team_id:
                team_members.setdefault(team_id, []).append(tag)
            else:
                ungrouped.append(tag)

        sections: list[str] = []
        for tid, members in team_members.items():
            team_def = org.teams.get(tid)
            team_label = team_def.label if team_def else tid
            sections.append(f"**{team_label}**: {' '.join(members)}")
        if ungrouped:
            sections.append(f"**å…¶ä»–**: {' '.join(ungrouped)}")

        if sections:
            prompt += (
                "\n\n---\n\n## å¯å§”æ´¾çš„åŒäº‹\n\n"
                "A=è‡ªä¸»æ‰§è¡Œ B=éœ€Kaiç¡®è®¤ C=çœ‹åœºæ™¯ã€‚"
                "ç”¨ delegate/delegate_async/delegate_chain/route è°ƒç”¨ã€‚\n\n"
                + "\n".join(sections)
            )

    from crew.permission import PermissionGuard

    guard = PermissionGuard(match)

    # ä» employee çš„ tools åˆ—è¡¨ä¸­ç­›é€‰ agent tools
    agent_tool_names = [t for t in (match.tools or []) if t in AGENT_TOOLS]
    tool_schemas, deferred_names = employee_tools_to_schemas(agent_tool_names)
    loaded_deferred: set[str] = set()  # å·²åŠ è½½çš„å»¶è¿Ÿå·¥å…·

    use_model = model or match.model or "claude-sonnet-4-20250514"
    provider = detect_provider(use_model)
    # base_url å¼ºåˆ¶èµ° OpenAI å…¼å®¹è·¯å¾„ï¼Œæ¶ˆæ¯æ ¼å¼ä¹Ÿè¦å¯¹åº”
    is_anthropic = provider == Provider.ANTHROPIC and not match.base_url

    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼ˆå«å†å²å¯¹è¯ï¼‰
    messages: list[dict[str, Any]] = []
    if message_history:
        for h in message_history:
            messages.append({"role": h["role"], "content": h["content"]})

    task_text = user_message or args.get("task", "è¯·å¼€å§‹æ‰§è¡Œä¸Šè¿°ä»»åŠ¡ã€‚")
    messages.append({"role": "user", "content": task_text})

    total_input = 0
    total_output = 0
    final_content = ""
    rounds = 0

    # è§£æ agent_idï¼ˆä» match çš„ agent_id å±æ€§ï¼Œæˆ–å‚æ•°ï¼‰
    effective_agent_id = agent_id or getattr(match, "agent_id", None)

    import crew.webhook as _wh
    _max_rounds = getattr(_wh, "_MAX_TOOL_ROUNDS", _MAX_TOOL_ROUNDS)
    for rounds in range(_max_rounds):  # noqa: B007
        result = await aexecute_with_tools(
            system_prompt=prompt,
            messages=messages,
            tools=tool_schemas,
            api_key=match.api_key or None,
            model=use_model,
            max_tokens=4096,
            base_url=match.base_url or None,
            fallback_model=match.fallback_model or None,
            fallback_api_key=match.fallback_api_key or None,
            fallback_base_url=match.fallback_base_url or None,
        )
        total_input += result.input_tokens
        total_output += result.output_tokens

        if not result.has_tool_calls:
            final_content = result.content
            break

        # â”€â”€ å¤„ç† tool calls â”€â”€
        if is_anthropic:
            assistant_content: list[dict[str, Any]] = []
            if result.content:
                assistant_content.append({"type": "text", "text": result.content})
            for tc in result.tool_calls:
                assistant_content.append({
                    "type": "tool_use",
                    "id": tc.id,
                    "name": tc.name,
                    "input": tc.arguments,
                })
            messages.append({"role": "assistant", "content": assistant_content})

            tool_results: list[dict[str, Any]] = []
            finished = False
            for tc in result.tool_calls:
                if tc.name == "load_tools":
                    # â”€â”€ å»¶è¿ŸåŠ è½½å·¥å…·ï¼ˆæ”¯æŒæŠ€èƒ½åŒ…åï¼‰ â”€â”€
                    from crew.tool_schema import SKILL_PACKS, _make_load_tools_schema
                    requested = {n.strip() for n in tc.arguments.get("names", "").split(",") if n.strip()}
                    # å±•å¼€æŠ€èƒ½åŒ…åä¸ºå·¥å…·å
                    expanded: set[str] = set()
                    for rn in requested:
                        if rn in SKILL_PACKS:
                            expanded |= SKILL_PACKS[rn]["tools"]
                        else:
                            expanded.add(rn)
                    newly = []
                    for tn in sorted(expanded):
                        if tn in deferred_names and tn not in loaded_deferred:
                            schema = get_tool_schema(tn)
                            if schema:
                                tool_schemas.append(schema)
                                loaded_deferred.add(tn)
                                newly.append(tn)
                    remaining = deferred_names - loaded_deferred
                    if not remaining:
                        tool_schemas = [s for s in tool_schemas if s["name"] != "load_tools"]
                    else:
                        new_load_schema = _make_load_tools_schema(remaining)
                        for s in tool_schemas:
                            if s["name"] == "load_tools":
                                s["description"] = new_load_schema["description"]
                    load_msg = f"å·²åŠ è½½: {', '.join(newly)}ã€‚ç°åœ¨å¯ä»¥ç›´æ¥è°ƒç”¨è¿™äº›å·¥å…·ã€‚" if newly else "è¿™äº›å·¥å…·å·²åŠ è½½ã€‚"
                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": tc.id,
                        "content": load_msg,
                    })
                    continue
                tool_output = await _handle_tool_call(
                    ctx, name, tc.name, tc.arguments, effective_agent_id, guard=guard,
                    max_visibility=max_visibility,
                )
                if tool_output is None:
                    # finish tool
                    final_content = tc.arguments.get("result", result.content)
                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": tc.id,
                        "content": final_content,
                    })
                    finished = True
                else:
                    tool_results.append({
                        "type": "tool_result",
                        "tool_use_id": tc.id,
                        "content": tool_output[:10000],
                    })
            messages.append({"role": "user", "content": tool_results})
            if finished:
                break
        else:
            assistant_msg: dict[str, Any] = {
                "role": "assistant",
                "content": result.content or "",
                "tool_calls": [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.name,
                            "arguments": __import__("json").dumps(
                                tc.arguments, ensure_ascii=False
                            ),
                        },
                    }
                    for tc in result.tool_calls
                ],
            }
            messages.append(assistant_msg)

            finished = False
            for tc in result.tool_calls:
                if tc.name == "load_tools":
                    # â”€â”€ å»¶è¿ŸåŠ è½½å·¥å…·ï¼ˆæ”¯æŒæŠ€èƒ½åŒ…åï¼‰ â”€â”€
                    from crew.tool_schema import SKILL_PACKS, _make_load_tools_schema
                    requested = {n.strip() for n in tc.arguments.get("names", "").split(",") if n.strip()}
                    expanded: set[str] = set()
                    for rn in requested:
                        if rn in SKILL_PACKS:
                            expanded |= SKILL_PACKS[rn]["tools"]
                        else:
                            expanded.add(rn)
                    newly = []
                    for tn in sorted(expanded):
                        if tn in deferred_names and tn not in loaded_deferred:
                            schema = get_tool_schema(tn)
                            if schema:
                                tool_schemas.append(schema)
                                loaded_deferred.add(tn)
                                newly.append(tn)
                    remaining = deferred_names - loaded_deferred
                    if not remaining:
                        tool_schemas = [s for s in tool_schemas if s["name"] != "load_tools"]
                    else:
                        new_load_schema = _make_load_tools_schema(remaining)
                        for s in tool_schemas:
                            if s["name"] == "load_tools":
                                s["description"] = new_load_schema["description"]
                    load_msg = f"å·²åŠ è½½: {', '.join(newly)}ã€‚ç°åœ¨å¯ä»¥ç›´æ¥è°ƒç”¨è¿™äº›å·¥å…·ã€‚" if newly else "è¿™äº›å·¥å…·å·²åŠ è½½ã€‚"
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tc.id,
                        "content": load_msg,
                    })
                    continue
                tool_output = await _handle_tool_call(
                    ctx, name, tc.name, tc.arguments, effective_agent_id, guard=guard,
                    max_visibility=max_visibility,
                )
                if tool_output is None:
                    final_content = tc.arguments.get("result", result.content)
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tc.id,
                        "content": final_content,
                    })
                    finished = True
                else:
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tc.id,
                        "content": tool_output[:10000],
                    })
            if finished:
                break
    else:
        final_content = result.content or "è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨è½®æ¬¡é™åˆ¶ã€‚"

    return {
        "employee": name,
        "prompt": prompt[:500],
        "output": final_content,
        "model": use_model,
        "input_tokens": total_input,
        "output_tokens": total_output,
        "tool_rounds": rounds,
        "base_url": match.base_url or "",
    }


async def _handle_tool_call(
    ctx: _AppContext,
    employee_name: str,
    tool_name: str,
    arguments: dict[str, Any],
    agent_id: int | None,
    guard: Any | None = None,
    max_visibility: str = "open",
) -> str | None:
    """å¤„ç†å•ä¸ª tool callï¼Œè¿”å›ç»“æœå­—ç¬¦ä¸²ã€‚è¿”å› None è¡¨ç¤º finish tool."""
    from crew.tool_schema import is_finish_tool

    if is_finish_tool(tool_name):
        return None

    # æƒé™æ£€æŸ¥
    if guard is not None:
        denied_msg = guard.check_soft(tool_name)
        if denied_msg:
            logger.warning("æƒé™æ‹’ç»: %s.%s", employee_name, tool_name)
            return f"[æƒé™æ‹’ç»] {denied_msg}"

    if tool_name == "add_memory":
        from crew.memory import MemoryStore
        project_dir = ctx.project_dir if ctx else Path(".")
        store = MemoryStore(project_dir=project_dir)
        # ç§èŠæ—¶é»˜è®¤ privateï¼ŒLLM ä¹Ÿå¯æ˜¾å¼æŒ‡å®š
        default_vis = "private" if max_visibility == "private" else "open"
        entry = store.add(
            employee=employee_name,
            category=arguments.get("category", "finding"),
            content=arguments.get("content", ""),
            source_session="",
            visibility=arguments.get("visibility", default_vis),
        )
        logger.info("è®°å¿†ä¿å­˜: %s â†’ %s (visibility=%s)", employee_name, entry.content[:60], entry.visibility)
        return "å·²è®°ä½ã€‚"

    if tool_name == "delegate":
        logger.info("å§”æ´¾: %s â†’ %s", employee_name, arguments.get("employee_name"))
        import crew.webhook as _wh
        return await _wh._delegate_employee(
            ctx,
            arguments.get("employee_name", ""),
            arguments.get("task", ""),
        )

    # æ³¨å…¥ _max_visibility åˆ° read_notes / create_note å·¥å…·
    if tool_name in ("read_notes", "create_note"):
        arguments.setdefault("_max_visibility", max_visibility)
        if tool_name == "create_note" and max_visibility == "private":
            arguments.setdefault("visibility", "private")

    handler = _TOOL_HANDLERS.get(tool_name)
    if handler:
        try:
            logger.info("å·¥å…·è°ƒç”¨: %s.%s(%s)", employee_name, tool_name, list(arguments.keys()))
            return await handler(arguments, agent_id=agent_id, ctx=ctx)
        except Exception as e:
            logger.warning("å·¥å…· %s æ‰§è¡Œå¤±è´¥: %s", tool_name, e)
            return f"å·¥å…·æ‰§è¡Œå¤±è´¥: {e}"

    return f"å·¥å…· '{tool_name}' ä¸å¯ç”¨ã€‚"


async def _execute_employee(
    ctx: _AppContext,
    name: str,
    args: dict[str, str],
    agent_id: int | None = None,
    model: str | None = None,
    user_message: "str | list[dict[str, Any]] | None" = None,
    message_history: list[dict[str, Any]] | None = None,
) -> dict[str, Any]:
    """æ‰§è¡Œå•ä¸ªå‘˜å·¥."""
    from crew.discovery import discover_employees
    from crew.engine import CrewEngine

    discovery = discover_employees(project_dir=ctx.project_dir)
    match = discovery.get(name)

    if match is None:
        raise EmployeeNotFoundError(name)

    # å¦‚æœå‘˜å·¥æœ‰ agent toolsï¼Œä½¿ç”¨å¸¦å·¥å…·çš„ agent loop
    from crew.tool_schema import AGENT_TOOLS

    if any(t in AGENT_TOOLS for t in (match.tools or [])):
        import crew.webhook as _wh
        return await _wh._execute_employee_with_tools(
            ctx, name, args, agent_id=agent_id, model=model,
            user_message=user_message,
            message_history=message_history,
        )

    # è·å– agent èº«ä»½
    agent_identity = None
    if agent_id:
        try:
            from crew.id_client import afetch_agent_identity
            agent_identity = await afetch_agent_identity(agent_id)
        except Exception as e:
            logger.debug("agent èº«ä»½è·å–å¤±è´¥ (agent_id=%s): %s", agent_id, e)

    engine = CrewEngine(project_dir=ctx.project_dir)
    # ä» args ä¸­æå– _max_visibilityï¼ˆé£ä¹¦ dispatch ä¼ å…¥ï¼‰
    max_visibility = args.pop("_max_visibility", "open") if isinstance(args, dict) else "open"
    prompt = engine.prompt(match, args=args, agent_identity=agent_identity, max_visibility=max_visibility)

    # å°è¯•æ‰§è¡Œ LLM è°ƒç”¨ï¼ˆexecutor è‡ªåŠ¨ä»ç¯å¢ƒå˜é‡è§£æ API keyï¼‰
    try:
        from crew.executor import aexecute_prompt

        use_model = model or match.model or "claude-sonnet-4-20250514"
        exec_kwargs = dict(
            system_prompt=prompt,
            api_key=match.api_key or None,
            model=use_model,
            stream=False,
            base_url=match.base_url or None,
            fallback_model=match.fallback_model or None,
            fallback_api_key=match.fallback_api_key or None,
            fallback_base_url=match.fallback_base_url or None,
        )
        if user_message:
            exec_kwargs["user_message"] = user_message
        result = await aexecute_prompt(**exec_kwargs)
    except (ValueError, ImportError):
        result = None

    if result is not None:
        return {
            "employee": name,
            "prompt": prompt,
            "output": result.content,
            "model": result.model,
            "input_tokens": result.input_tokens,
            "output_tokens": result.output_tokens,
            "base_url": match.base_url or "",
        }

    return {"employee": name, "prompt": prompt, "output": ""}


async def _stream_employee(
    ctx: _AppContext,
    name: str,
    args: dict[str, str],
    agent_id: int | None = None,
    model: str | None = None,
) -> Any:
    """SSE æµå¼æ‰§è¡Œå•ä¸ªå‘˜å·¥."""
    import json as _json

    from starlette.responses import StreamingResponse

    def _dumps(obj: Any) -> str:
        return _json.dumps(obj, ensure_ascii=False)

    from crew.discovery import discover_employees
    from crew.engine import CrewEngine

    result = discover_employees(project_dir=ctx.project_dir)
    match = result.get(name)

    if match is None:
        async def _error():
            yield f"event: error\ndata: {_dumps({'error': f'æœªæ‰¾åˆ°å‘˜å·¥: {name}'})}\n\n"
        return StreamingResponse(_error(), media_type="text/event-stream")

    # è·å– agent èº«ä»½
    agent_identity = None
    if agent_id:
        try:
            from crew.id_client import afetch_agent_identity

            agent_identity = await afetch_agent_identity(agent_id)
        except Exception as e:
            logger.debug("agent èº«ä»½è·å–å¤±è´¥ (agent_id=%s): %s", agent_id, e)

    engine = CrewEngine(project_dir=ctx.project_dir)
    prompt = engine.prompt(match, args=args, agent_identity=agent_identity)

    async def _generate():
        done_sent = False
        try:
            from crew.executor import aexecute_prompt

            use_model = model or match.model or "claude-sonnet-4-20250514"
            stream_iter = await asyncio.wait_for(
                aexecute_prompt(
                    system_prompt=prompt,
                    api_key=match.api_key or None,
                    model=use_model,
                    stream=True,
                    base_url=match.base_url or None,
                    fallback_model=match.fallback_model or None,
                    fallback_api_key=match.fallback_api_key or None,
                    fallback_base_url=match.fallback_base_url or None,
                ),
                timeout=300,
            )

            async for chunk in stream_iter:
                yield f"data: {_dumps({'token': chunk})}\n\n"

            # æµç»“æŸåå‘é€å®Œæ•´çš„ result
            result = getattr(stream_iter, "result", None)
            if result:
                yield f"event: done\ndata: {_dumps({'employee': name, 'model': result.model, 'input_tokens': result.input_tokens, 'output_tokens': result.output_tokens})}\n\n"
            else:
                yield f"event: done\ndata: {_dumps({'employee': name})}\n\n"
            done_sent = True
        except asyncio.TimeoutError:
            yield f"event: error\ndata: {_dumps({'error': 'stream timeout (300s)'})}\n\n"
            done_sent = True
        except Exception as exc:
            yield f"event: error\ndata: {_dumps({'error': str(exc)[:500]})}\n\n"
            done_sent = True
        finally:
            if not done_sent:
                yield f"event: error\ndata: {_dumps({'error': 'stream interrupted'})}\n\n"

    return StreamingResponse(_generate(), media_type="text/event-stream")


async def _resume_incomplete_pipelines(ctx: _AppContext) -> None:
    """æ¢å¤æœªå®Œæˆçš„ pipeline ä»»åŠ¡ï¼ˆæœåŠ¡é‡å¯åï¼‰."""
    for record in ctx.registry.list_recent(n=100):
        if record.status != "running" or record.target_type != "pipeline" or not record.checkpoint:
            continue

        checkpoint = record.checkpoint
        pipeline_name = checkpoint.get("pipeline_name", record.target_name)
        logger.info("æ¢å¤ pipeline ä»»åŠ¡: %s (task=%s)", pipeline_name, record.task_id)

        try:
            from crew.pipeline import aresume_pipeline, discover_pipelines, load_pipeline

            pipelines = discover_pipelines(project_dir=ctx.project_dir)
            if pipeline_name not in pipelines:
                ctx.registry.update(record.task_id, "failed", error=f"æ¢å¤å¤±è´¥: æœªæ‰¾åˆ° pipeline {pipeline_name}")
                continue

            pipeline = load_pipeline(pipelines[pipeline_name])

            def _make_callback(tid):
                def cb(step_result, checkpoint_data):
                    ctx.registry.update_checkpoint(tid, checkpoint_data)
                return cb

            result = await aresume_pipeline(
                pipeline,
                checkpoint=checkpoint,
                initial_args=record.args,
                project_dir=ctx.project_dir,
                api_key=None,
                on_step_complete=_make_callback(record.task_id),
            )
            ctx.registry.update(record.task_id, "completed", result=result.model_dump(mode="json"))
        except Exception as e:
            logger.exception("æ¢å¤ä»»åŠ¡å¤±è´¥: %s", record.task_id)
            ctx.registry.update(record.task_id, "failed", error=f"æ¢å¤å¤±è´¥: {e}")
