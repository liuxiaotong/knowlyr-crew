"""å¤–éƒ¨æœåŠ¡å·¥å…·å‡½æ•° â€” Notionã€RSSã€ç¿»è¯‘ã€å¤©æ°”ã€æœç´¢ç­‰."""

from __future__ import annotations

from typing import TYPE_CHECKING

from crew.webhook_context import (
    _NOTION_API_BASE,
    _NOTION_API_KEY,
    _NOTION_VERSION,
)
from crew.webhook_tools.feishu import _CITY_CODES

if TYPE_CHECKING:
    from crew.webhook_context import _AppContext


async def _tool_web_search(
    args: dict, *, agent_id: str | None = None, ctx: _AppContext | None = None
) -> str:
    """æœç´¢äº’è”ç½‘ï¼ˆBing cnï¼‰."""
    import re

    import httpx

    query = args.get("query", "")
    max_results = min(args.get("max_results", 5), 10)
    if not query:
        return "é”™è¯¯ï¼šquery ä¸èƒ½ä¸ºç©º"

    try:
        async with httpx.AsyncClient(timeout=15.0, follow_redirects=True) as client:
            resp = await client.get(
                "https://cn.bing.com/search",
                params={"q": query, "count": max_results},
                headers={
                    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36",
                    "Accept-Language": "zh-CN,zh;q=0.9",
                },
            )

        results: list[str] = []
        for block in re.finditer(r'<li class="b_algo".*?</li>', resp.text, re.DOTALL):
            if len(results) >= max_results:
                break
            title_m = re.search(
                r'<a[^>]*href="([^"]*)"[^>]*>(.*?)</a>',
                block.group(),
                re.DOTALL,
            )
            snippet_m = re.search(r"<p[^>]*>(.*?)</p>", block.group(), re.DOTALL)
            if title_m:
                href = title_m.group(1)
                title = re.sub(r"<[^>]+>", "", title_m.group(2)).strip()
                snippet = re.sub(r"<[^>]+>", "", snippet_m.group(1)).strip() if snippet_m else ""
                if title or snippet:
                    results.append(f"{title}\n{snippet}\n{href}")

        if not results:
            return f"æœªæ‰¾åˆ°å…³äºã€Œ{query}ã€çš„æœç´¢ç»“æœ"
        return "\n\n---\n\n".join(results)
    except Exception as e:
        return f"æœç´¢å¤±è´¥: {e}"


async def _tool_weather(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """æŸ¥å¤©æ°”ï¼ˆå›½å†…åŸå¸‚ï¼‰."""
    import httpx

    city = (args.get("city") or "").strip().replace("å¸‚", "").replace("çœ", "")
    if not city:
        return "éœ€è¦åŸå¸‚åï¼Œå¦‚ï¼šä¸Šæµ·ã€åŒ—äº¬ã€æ­å·ã€‚"

    code = _CITY_CODES.get(city)
    if not code:
        avail = "ã€".join(list(_CITY_CODES.keys())[:20]) + "â€¦"
        return f"æš‚ä¸æ”¯æŒã€Œ{city}ã€ï¼Œæ”¯æŒçš„åŸå¸‚ï¼š{avail}"

    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            resp = await client.get(f"http://t.weather.itboy.net/api/weather/city/{code}")
            data = resp.json()

        if data.get("status") != 200:
            return f"æŸ¥è¯¢å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}"

        info = data.get("data", {})
        city_name = data.get("cityInfo", {}).get("city", city)
        now_temp = info.get("wendu", "?")
        humidity = info.get("shidu", "?")
        quality = info.get("quality", "")
        pm25 = info.get("pm25", "")

        forecast = info.get("forecast", [])
        lines = [f"{city_name} å½“å‰ {now_temp}â„ƒï¼Œæ¹¿åº¦ {humidity}"]
        if quality:
            lines[0] += f"ï¼Œç©ºæ°”{quality}"
            if pm25:
                lines[0] += f"(PM2.5:{pm25})"

        days = min(int(args.get("days", 3)), 7)
        for day in forecast[:days]:
            high = day.get("high", "").replace("é«˜æ¸© ", "")
            low = day.get("low", "").replace("ä½æ¸© ", "")
            weather_type = day.get("type", "")
            wind = day.get("fx", "")
            wind_level = day.get("fl", "")
            date = day.get("ymd", "")
            week = day.get("week", "")
            lines.append(f"{date}({week}) {weather_type} {low}~{high} {wind}{wind_level}")

        return "\n".join(lines)
    except Exception as e:
        return f"å¤©æ°”æŸ¥è¯¢å¤±è´¥: {e}"


async def _tool_exchange_rate(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """æŸ¥æ±‡ç‡."""
    import httpx

    base = (args.get("from") or args.get("base") or "USD").upper().strip()
    targets = (args.get("to") or "CNY").upper().strip()
    target_list = [t.strip() for t in targets.split(",") if t.strip()]

    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            resp = await client.get(f"https://api.exchangerate-api.com/v4/latest/{base}")
            data = resp.json()

        if "rates" not in data:
            return f"æŸ¥è¯¢å¤±è´¥: ä¸æ”¯æŒè´§å¸ {base}"

        rates = data["rates"]
        lines = [f"åŸºå‡†: 1 {base}"]
        for t in target_list:
            rate = rates.get(t)
            if rate is not None:
                lines.append(f"= {rate} {t}")
            else:
                lines.append(f"{t}: ä¸æ”¯æŒ")
        return "\n".join(lines)
    except Exception as e:
        return f"æ±‡ç‡æŸ¥è¯¢å¤±è´¥: {e}"


async def _tool_stock_price(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """æŸ¥è‚¡ä»·ï¼ˆAè‚¡/ç¾è‚¡ï¼‰."""
    import re

    import httpx

    symbol = (args.get("symbol") or "").strip()
    if not symbol:
        return "éœ€è¦è‚¡ç¥¨ä»£ç ï¼Œå¦‚ï¼šsh600519ï¼ˆèŒ…å°ï¼‰ã€gb_aaplï¼ˆè‹¹æœï¼‰ã€‚"

    # è§„èŒƒåŒ–ï¼šçº¯æ•°å­—é»˜è®¤ä¸ºæ²ªå¸‚Aè‚¡
    sym = symbol.lower()
    if re.match(r"^\d{6}$", sym):
        sym = f"sh{sym}" if sym.startswith("6") else f"sz{sym}"
    elif re.match(r"^[a-z]{1,5}$", sym):
        sym = f"gb_{sym}"

    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            resp = await client.get(
                f"https://hq.sinajs.cn/list={sym}",
                headers={"Referer": "https://finance.sina.com.cn"},
            )
        text = resp.text.strip()
        if not text or '=""' in text:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨: {symbol}"

        # è§£æ Sina è¡Œæƒ…æ•°æ®
        m = re.search(r'="(.+)"', text)
        if not m:
            return f"æ•°æ®è§£æå¤±è´¥: {symbol}"

        fields = m.group(1).split(",")
        if sym.startswith("gb_"):
            # ç¾è‚¡æ ¼å¼: åç§°,ç°ä»·,æ¶¨è·Œå¹…%,æ—¶é—´,æ¶¨è·Œé¢,å¼€ç›˜,æœ€é«˜,æœ€ä½,...
            if len(fields) < 4:
                return f"æ•°æ®ä¸å®Œæ•´: {symbol}"
            name, price, change_pct = fields[0], fields[1], fields[2]
            return f"{name} ({symbol.upper()})\nç°ä»·: ${price}  æ¶¨è·Œ: {change_pct}%"
        else:
            # Aè‚¡æ ¼å¼: åç§°,ä»Šå¼€,æ˜¨æ”¶,ç°ä»·,æœ€é«˜,æœ€ä½,...
            if len(fields) < 6:
                return f"æ•°æ®ä¸å®Œæ•´: {symbol}"
            name, today_open, prev_close, price, high, low = fields[:6]
            try:
                change = float(price) - float(prev_close)
                change_pct = change / float(prev_close) * 100
                sign = "+" if change >= 0 else ""
                return f"{name} ({symbol.upper()})\nç°ä»·: Â¥{price}  æ¶¨è·Œ: {sign}{change:.2f} ({sign}{change_pct:.2f}%)\nä»Šå¼€: {today_open}  æœ€é«˜: {high}  æœ€ä½: {low}"
            except (ValueError, ZeroDivisionError):
                return f"{name} ({symbol.upper()})\nç°ä»·: Â¥{price}"
    except Exception as e:
        return f"è‚¡ä»·æŸ¥è¯¢å¤±è´¥: {e}"


def _notion_blocks_to_text(blocks: list[dict]) -> str:
    """å°† Notion blocks è½¬ä¸ºçº¯æ–‡æœ¬."""
    parts = []
    for block in blocks:
        btype = block.get("type", "")
        data = block.get(btype, {})
        rich_text = data.get("rich_text", [])
        text = "".join(rt.get("plain_text", "") for rt in rich_text)
        if btype.startswith("heading"):
            parts.append(f"\n{text}\n")
        elif btype == "to_do":
            checked = "x" if data.get("checked") else " "
            parts.append(f"[{checked}] {text}")
        elif btype == "code":
            parts.append(f"```\n{text}\n```")
        elif text:
            parts.append(text)
    return "\n".join(parts)


async def _tool_notion_search(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """æœç´¢ Notion é¡µé¢."""
    import httpx

    if not _NOTION_API_KEY:
        return "Notion æœªé…ç½®ã€‚è¯·è®¾ç½® NOTION_API_KEY ç¯å¢ƒå˜é‡ã€‚"

    query = (args.get("query") or "").strip()
    limit = min(args.get("limit", 10), 20)
    if not query:
        return "æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©ºã€‚"

    headers = {
        "Authorization": f"Bearer {_NOTION_API_KEY}",
        "Notion-Version": _NOTION_VERSION,
        "Content-Type": "application/json",
    }
    async with httpx.AsyncClient(timeout=30.0) as client:
        resp = await client.post(
            f"{_NOTION_API_BASE}/search",
            json={"query": query, "page_size": limit},
            headers=headers,
        )
    if resp.status_code != 200:
        return f"Notion API é”™è¯¯ {resp.status_code}: {resp.text[:500]}"

    results = resp.json().get("results", [])
    if not results:
        return "æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„é¡µé¢ã€‚"

    lines = []
    for r in results[:limit]:
        obj_type = r.get("object", "page")
        url = r.get("url", "")
        edited = r.get("last_edited_time", "")[:10]
        # æå–æ ‡é¢˜
        props = r.get("properties", {})
        title_prop = props.get("title", props.get("Name", {}))
        title_arr = title_prop.get("title", []) if isinstance(title_prop, dict) else []
        title = "".join(t.get("plain_text", "") for t in title_arr) or "æ— æ ‡é¢˜"
        lines.append(f"[{obj_type}] {title} (edited: {edited})\n{url}")
    return "\n---\n".join(lines)


async def _tool_notion_read(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """è¯»å– Notion é¡µé¢å†…å®¹."""
    import httpx

    if not _NOTION_API_KEY:
        return "Notion æœªé…ç½®ã€‚è¯·è®¾ç½® NOTION_API_KEY ç¯å¢ƒå˜é‡ã€‚"

    page_id = (args.get("page_id") or "").strip().replace("-", "")
    if not page_id:
        return "ç¼ºå°‘ page_idã€‚"

    headers = {
        "Authorization": f"Bearer {_NOTION_API_KEY}",
        "Notion-Version": _NOTION_VERSION,
    }
    all_blocks: list[dict] = []
    next_cursor = None

    async with httpx.AsyncClient(timeout=30.0) as client:
        for _ in range(5):  # æœ€å¤šå– 5 é¡µ
            params: dict = {"page_size": 100}
            if next_cursor:
                params["start_cursor"] = next_cursor
            resp = await client.get(
                f"{_NOTION_API_BASE}/blocks/{page_id}/children",
                params=params,
                headers=headers,
            )
            if resp.status_code != 200:
                return f"Notion API é”™è¯¯ {resp.status_code}: {resp.text[:500]}"
            data = resp.json()
            all_blocks.extend(data.get("results", []))
            if not data.get("has_more"):
                break
            next_cursor = data.get("next_cursor")

    text = _notion_blocks_to_text(all_blocks)
    if not text.strip():
        return f"é¡µé¢ {page_id} å†…å®¹ä¸ºç©ºã€‚"
    if len(text) > 9500:
        return text[:9500] + f"\n\n[å†…å®¹å·²æˆªæ–­ï¼Œå…± {len(text)} å­—ç¬¦]"
    return text


async def _tool_notion_create(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """åœ¨ Notion åˆ›å»ºæ–°é¡µé¢."""
    import httpx

    if not _NOTION_API_KEY:
        return "Notion æœªé…ç½®ã€‚è¯·è®¾ç½® NOTION_API_KEY ç¯å¢ƒå˜é‡ã€‚"

    parent_id = (args.get("parent_id") or "").strip().replace("-", "")
    title = (args.get("title") or "").strip()
    content = args.get("content", "")
    if not parent_id or not title:
        return "éœ€è¦ parent_id å’Œ titleã€‚"

    children = []
    for para in content.split("\n\n")[:100]:
        if para.strip():
            children.append(
                {
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [{"type": "text", "text": {"content": para.strip()}}]
                    },
                }
            )

    headers = {
        "Authorization": f"Bearer {_NOTION_API_KEY}",
        "Notion-Version": _NOTION_VERSION,
        "Content-Type": "application/json",
    }
    async with httpx.AsyncClient(timeout=30.0) as client:
        resp = await client.post(
            f"{_NOTION_API_BASE}/pages",
            json={
                "parent": {"page_id": parent_id},
                "properties": {"title": {"title": [{"text": {"content": title}}]}},
                "children": children,
            },
            headers=headers,
        )
    if resp.status_code not in (200, 201):
        return f"Notion åˆ›å»ºå¤±è´¥ {resp.status_code}: {resp.text[:500]}"

    url = resp.json().get("url", "")
    return f"é¡µé¢å·²åˆ›å»ºï¼š{title}\n{url}"


# â”€â”€ ä¿¡æ¯é‡‡é›†å·¥å…· â”€â”€


async def _tool_read_url(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """è¯»å–ç½‘é¡µæ­£æ–‡."""
    import ipaddress
    import re
    from urllib.parse import urlparse

    import httpx

    url = (args.get("url") or "").strip()
    if not url:
        return "ç¼ºå°‘ URLã€‚"

    # SSRF é˜²æŠ¤ï¼šä»…å…è®¸ http/httpsï¼Œé˜»æ­¢ç§æœ‰/ä¿ç•™ IP
    parsed = urlparse(url)
    if parsed.scheme not in ("http", "https"):
        return "ä»…æ”¯æŒ http/https åè®®ã€‚"
    hostname = parsed.hostname or ""
    if not hostname:
        return "æ— æ•ˆ URLã€‚"

    import socket

    # å…ˆè§£æ DNSï¼Œå†æ ¡éªŒ IPï¼Œé˜²æ­¢ DNS rebinding ç»•è¿‡
    try:
        addr_infos = socket.getaddrinfo(
            hostname, parsed.port or (443 if parsed.scheme == "https" else 80)
        )
    except socket.gaierror:
        return f"DNS è§£æå¤±è´¥: {hostname}"
    for family, _type, _proto, _canonname, sockaddr in addr_infos:
        try:
            addr = ipaddress.ip_address(sockaddr[0])
            if addr.is_private or addr.is_loopback or addr.is_link_local or addr.is_reserved:
                return "ä¸å…è®¸è®¿é—®å†…ç½‘åœ°å€ã€‚"
        except ValueError:
            pass
    if hostname in ("localhost", "metadata.google.internal"):
        return "ä¸å…è®¸è®¿é—®å†…ç½‘åœ°å€ã€‚"

    try:
        async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
            resp = await client.get(url, headers={"User-Agent": "Mozilla/5.0"})
        html = resp.text
    except Exception as e:
        return f"è¯·æ±‚å¤±è´¥: {e}"

    # ç®€å•çš„ HTML â†’ çº¯æ–‡æœ¬æå–
    html = re.sub(r"<script[^>]*>.*?</script>", "", html, flags=re.DOTALL | re.IGNORECASE)
    html = re.sub(r"<style[^>]*>.*?</style>", "", html, flags=re.DOTALL | re.IGNORECASE)
    html = re.sub(r"<nav[^>]*>.*?</nav>", "", html, flags=re.DOTALL | re.IGNORECASE)
    html = re.sub(r"<footer[^>]*>.*?</footer>", "", html, flags=re.DOTALL | re.IGNORECASE)
    html = re.sub(r"<header[^>]*>.*?</header>", "", html, flags=re.DOTALL | re.IGNORECASE)

    # æå– <article> æˆ– <main>ï¼Œå¦åˆ™å– <body>
    for tag in ("article", "main"):
        m = re.search(rf"<{tag}[^>]*>(.*?)</{tag}>", html, re.DOTALL | re.IGNORECASE)
        if m:
            html = m.group(1)
            break

    text = re.sub(r"<[^>]+>", " ", html)
    text = re.sub(r"\s+", " ", text).strip()

    if not text:
        return "æ— æ³•æå–é¡µé¢å†…å®¹ã€‚"
    if len(text) > 9500:
        return text[:9500] + f"\n\n[å†…å®¹å·²æˆªæ–­ï¼Œå…± {len(text)} å­—ç¬¦]"
    return text


async def _tool_rss_read(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """è¯»å– RSS/Atom è®¢é˜…æº."""
    import re

    try:
        import defusedxml.ElementTree as ET
    except ImportError:
        import logging as _logging
        import xml.etree.ElementTree as ET  # noqa: S405

        _logging.getLogger(__name__).warning(
            "defusedxml æœªå®‰è£…ï¼ŒRSS è§£æä½¿ç”¨æ ‡å‡†åº“ xml.etree.ElementTreeï¼ˆæ—  XXE é˜²æŠ¤ï¼‰ã€‚"
            "å»ºè®®å®‰è£…: pip install 'knowlyr-crew[webhook]'"
        )

    import httpx

    url = (args.get("url") or "").strip()
    limit = min(args.get("limit", 10), 30)
    if not url:
        return "ç¼ºå°‘ RSS URLã€‚"

    try:
        async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
            resp = await client.get(url, headers={"User-Agent": "Mozilla/5.0"})
        root = ET.fromstring(resp.text)
    except Exception as e:
        return f"RSS è§£æå¤±è´¥: {e}"

    entries = []
    # RSS 2.0: <channel><item>
    for item in root.iter("item"):
        title = (item.findtext("title") or "").strip()
        link = (item.findtext("link") or "").strip()
        desc = (item.findtext("description") or "")[:200].strip()
        desc = re.sub(r"<[^>]+>", "", desc)  # strip HTML
        if title:
            entries.append(f"{title}\n{desc}\n{link}")

    # Atom: <entry>
    ns = {"atom": "http://www.w3.org/2005/Atom"}
    for entry in root.iter("{http://www.w3.org/2005/Atom}entry"):
        title = (
            entry.findtext("atom:title", "", ns)
            or entry.findtext("{http://www.w3.org/2005/Atom}title")
            or ""
        ).strip()
        link_el = entry.find("atom:link", ns) or entry.find("{http://www.w3.org/2005/Atom}link")
        link = link_el.get("href", "") if link_el is not None else ""
        summary = (
            entry.findtext("atom:summary", "", ns)
            or entry.findtext("{http://www.w3.org/2005/Atom}summary")
            or ""
        )[:200].strip()
        summary = re.sub(r"<[^>]+>", "", summary)
        if title:
            entries.append(f"{title}\n{summary}\n{link}")

    if not entries:
        return "è®¢é˜…æºä¸­æ²¡æœ‰æ‰¾åˆ°æ¡ç›®ã€‚"

    return "\n---\n".join(entries[:limit])


# â”€â”€ ç”Ÿæ´»åŠ©æ‰‹å·¥å…· â”€â”€


async def _tool_translate(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """ä¸­è‹±äº’è¯‘ï¼ˆMyMemory APIï¼‰."""
    import httpx

    text = (args.get("text") or "").strip()
    if not text:
        return "éœ€è¦ç¿»è¯‘çš„æ–‡æœ¬ã€‚"
    if len(text) > 2000:
        return "æ–‡æœ¬è¿‡é•¿ï¼Œæœ€å¤š 2000 å­—ç¬¦ã€‚"

    from_lang = (args.get("from_lang") or "auto").strip().lower()
    to_lang = (args.get("to_lang") or "").strip().lower()

    # è‡ªåŠ¨æ£€æµ‹ï¼šCJK å æ¯” > 30% â†’ ä¸­â†’è‹±ï¼Œå¦åˆ™è‹±â†’ä¸­
    if from_lang == "auto":
        cjk = sum(1 for c in text if "\u4e00" <= c <= "\u9fff")
        if cjk / max(len(text), 1) > 0.3:
            from_lang, to_lang = "zh-CN", to_lang or "en-GB"
        else:
            from_lang, to_lang = "en-GB", to_lang or "zh-CN"
    else:
        _lang_map = {
            "zh": "zh-CN",
            "en": "en-GB",
            "ja": "ja-JP",
            "ko": "ko-KR",
            "fr": "fr-FR",
            "de": "de-DE",
        }
        from_lang = _lang_map.get(from_lang, from_lang)
        to_lang = (
            _lang_map.get(to_lang, to_lang)
            if to_lang
            else ("en-GB" if "zh" in from_lang else "zh-CN")
        )

    try:
        async with httpx.AsyncClient(timeout=15.0) as client:
            resp = await client.get(
                "https://api.mymemory.translated.net/get",
                params={"q": text, "langpair": f"{from_lang}|{to_lang}"},
            )
            data = resp.json()
        translated = data.get("responseData", {}).get("translatedText", "")
        if not translated:
            return "ç¿»è¯‘å¤±è´¥ï¼Œæœªè·å¾—ç»“æœã€‚"
        return translated
    except Exception as e:
        return f"ç¿»è¯‘å¤±è´¥: {e}"


async def _tool_countdown(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """è®¡ç®—è·ç¦»ç›®æ ‡æ—¥æœŸçš„å€’è®¡æ—¶."""
    from datetime import datetime, timedelta
    from datetime import timezone as _tz

    tz_cn = _tz(timedelta(hours=8))
    date_str = (args.get("date") or "").strip()
    event = (args.get("event") or "").strip()

    if not date_str:
        return "éœ€è¦ç›®æ ‡æ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DDã€‚"

    try:
        target = datetime.strptime(date_str, "%Y-%m-%d").replace(tzinfo=tz_cn)
    except ValueError:
        return f"æ—¥æœŸæ ¼å¼ä¸å¯¹: {date_str}ï¼Œéœ€è¦ YYYY-MM-DDã€‚"

    now = datetime.now(tz_cn)
    delta = target - now
    label = f"ã€Œ{event}ã€" if event else date_str

    if delta.total_seconds() < 0:
        days = abs(delta.days)
        return f"{label} å·²ç»è¿‡å»äº† {days} å¤©ã€‚"

    days = delta.days
    hours = delta.seconds // 3600
    if days == 0:
        return f"è·ç¦» {label} è¿˜æœ‰ {hours} å°æ—¶ã€‚"
    return f"è·ç¦» {label} è¿˜æœ‰ {days} å¤© {hours} å°æ—¶ã€‚"


async def _tool_trending(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """çƒ­æœèšåˆï¼ˆå¾®åš / çŸ¥ä¹ï¼‰."""
    import httpx

    platform = (args.get("platform") or "weibo").strip().lower()
    limit = min(args.get("limit", 15) or 15, 30)

    try:
        async with httpx.AsyncClient(timeout=15.0) as client:
            if platform == "zhihu":
                resp = await client.get(
                    "https://www.zhihu.com/api/v3/feed/topstory/hot-lists/total",
                    headers={"User-Agent": "Mozilla/5.0"},
                )
                data = resp.json()
                items = data.get("data", [])[:limit]
                if not items:
                    return "çŸ¥ä¹çƒ­æ¦œæš‚æ— æ•°æ®ã€‚"
                lines = []
                for i, item in enumerate(items, 1):
                    target = item.get("target", {})
                    title = target.get("title", "")
                    excerpt = target.get("excerpt", "")[:60]
                    lines.append(f"{i}. {title}\n   {excerpt}")
                return "ğŸ“Š çŸ¥ä¹çƒ­æ¦œ\n\n" + "\n".join(lines)
            else:
                # å¾®åšçƒ­æœ
                resp = await client.get(
                    "https://weibo.com/ajax/side/hotSearch",
                    headers={"User-Agent": "Mozilla/5.0"},
                )
                data = resp.json()
                items = data.get("data", {}).get("realtime", [])[:limit]
                if not items:
                    return "å¾®åšçƒ­æœæš‚æ— æ•°æ®ã€‚"
                lines = []
                for i, item in enumerate(items, 1):
                    word = item.get("word", "")
                    num = item.get("num", 0)
                    label_name = item.get("label_name", "")
                    tag = f" [{label_name}]" if label_name else ""
                    lines.append(f"{i}. {word}{tag}  ({num:,})")
                return "ğŸ”¥ å¾®åšçƒ­æœ\n\n" + "\n".join(lines)
    except Exception as e:
        return f"è·å–çƒ­æœå¤±è´¥: {e}"


# â”€â”€ é£ä¹¦è¡¨æ ¼å·¥å…· â”€â”€


async def _tool_summarize(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """é•¿æ–‡æ‘˜è¦ï¼ˆç”±æ¨¡å‹è‡ªèº«å®Œæˆï¼‰."""
    text = (args.get("text") or "").strip()
    if not text:
        return "éœ€è¦æ–‡æœ¬ã€‚"
    if len(text) > 50000:
        text = text[:50000] + "...(å·²æˆªæ–­)"

    style = (args.get("style") or "bullet").strip().lower()
    style_map = {
        "bullet": "ç”¨è¦ç‚¹åˆ—è¡¨æ€»ç»“",
        "paragraph": "ç”¨ä¸€æ®µè¯æ€»ç»“",
        "oneline": "ç”¨ä¸€å¥è¯æ€»ç»“",
    }
    instruction = style_map.get(style, style_map["bullet"])
    return f"[æ‘˜è¦ä»»åŠ¡] è¯·{instruction}ä»¥ä¸‹å†…å®¹ï¼š\n\n{text}"


async def _tool_sentiment(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """æƒ…æ„Ÿåˆ†æï¼ˆç”±æ¨¡å‹è‡ªèº«å®Œæˆï¼‰."""
    text = (args.get("text") or "").strip()
    if not text:
        return "éœ€è¦æ–‡æœ¬ã€‚"
    if len(text) > 10000:
        text = text[:10000] + "...(å·²æˆªæ–­)"

    return (
        f"[æƒ…æ„Ÿåˆ†æä»»åŠ¡] è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰ã€è¯­æ°”å’Œå…³é”®æƒ…ç»ªè¯ï¼š\n\n{text}"
    )


async def _tool_email_send(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """å‘é€é‚®ä»¶ï¼ˆæš‚æœªå¯¹æ¥ SMTPï¼‰."""
    to = (args.get("to") or "").strip()
    subject = (args.get("subject") or "").strip()
    if not to or not subject:
        return "éœ€è¦æ”¶ä»¶äººå’Œä¸»é¢˜ã€‚"
    return "é‚®ä»¶åŠŸèƒ½å°šæœªé…ç½® SMTPï¼Œæš‚æ—¶æ— æ³•å‘é€ã€‚è¯·ç›´æ¥é€šè¿‡é£ä¹¦æˆ–å…¶ä»–æ–¹å¼è”ç³»ã€‚"


async def _tool_qrcode(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """ç”ŸæˆäºŒç»´ç ."""
    from urllib.parse import quote

    data = (args.get("data") or "").strip()
    if not data:
        return "éœ€è¦ç¼–ç å†…å®¹ã€‚"

    size = args.get("size", 300) or 300
    encoded = quote(data, safe="")
    url = f"https://api.qrserver.com/v1/create-qr-code/?size={size}x{size}&data={encoded}"
    return f"äºŒç»´ç å·²ç”Ÿæˆï¼š\n{url}\n\nå†…å®¹: {data}"


async def _tool_express_track(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """å¿«é€’ç‰©æµæŸ¥è¯¢."""
    import httpx

    number = (args.get("number") or "").strip()
    if not number:
        return "éœ€è¦å¿«é€’å•å·ã€‚"

    company = (args.get("company") or "").strip()

    try:
        async with httpx.AsyncClient(timeout=15.0) as client:
            # å¿«é€’100 auto API
            url = "https://www.kuaidi100.com/query"
            params = {"type": company or "auto", "postid": number}
            resp = await client.get(url, params=params)
            data = resp.json()

        if data.get("status") != "200" and not data.get("data"):
            # å°è¯•å¤‡ç”¨æ ¼å¼
            msg = data.get("message") or data.get("msg") or "æœªæŸ¥åˆ°ç‰©æµä¿¡æ¯"
            return f"æŸ¥è¯¢å¤±è´¥: {msg}"

        traces = data.get("data", [])
        if not traces:
            return f"å¿«é€’å•å· {number} æš‚æ— ç‰©æµä¿¡æ¯ã€‚"

        com_name = data.get("com", company or "æœªçŸ¥")
        state_map = {
            "0": "è¿è¾“ä¸­",
            "1": "æ½æ”¶",
            "2": "ç–‘éš¾",
            "3": "å·²ç­¾æ”¶",
            "4": "é€€ç­¾",
            "5": "æ´¾ä»¶ä¸­",
            "6": "é€€å›",
        }
        state = state_map.get(str(data.get("state", "")), "æœªçŸ¥")

        lines = [f"ğŸ“¦ {com_name} {number} [{state}]", ""]
        for t in traces[:10]:
            time_str = t.get("ftime") or t.get("time", "")
            context = t.get("context", "")
            lines.append(f"  {time_str}  {context}")
        return "\n".join(lines)
    except Exception as e:
        return f"å¿«é€’æŸ¥è¯¢å¤±è´¥: {e}"


async def _tool_flight_info(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """èˆªç­æŸ¥è¯¢ï¼ˆæš‚ç”¨ web_search ä»£ç†ï¼‰."""
    flight_no = (args.get("flight_no") or "").strip().upper()
    if not flight_no:
        return "éœ€è¦èˆªç­å·ã€‚"

    date = (args.get("date") or "").strip()
    return f"èˆªç­æŸ¥è¯¢åŠŸèƒ½å¼€å‘ä¸­ã€‚è¯·ä½¿ç”¨ web_search æœç´¢ã€Œ{flight_no} {date} èˆªç­åŠ¨æ€ã€è·å–ä¿¡æ¯ã€‚"


async def _tool_aqi(
    args: dict,
    *,
    agent_id: str | None = None,
    ctx: _AppContext | None = None,
) -> str:
    """ç©ºæ°”è´¨é‡æŸ¥è¯¢."""
    import httpx

    city = (args.get("city") or "").strip()
    if not city:
        return "éœ€è¦åŸå¸‚åã€‚"

    # ä¸­æ–‡åŸå¸‚åæ˜ å°„
    city_map = {
        "ä¸Šæµ·": "shanghai",
        "åŒ—äº¬": "beijing",
        "å¹¿å·": "guangzhou",
        "æ·±åœ³": "shenzhen",
        "æ­å·": "hangzhou",
        "æˆéƒ½": "chengdu",
        "é‡åº†": "chongqing",
        "æ­¦æ±‰": "wuhan",
        "å—äº¬": "nanjing",
        "è¥¿å®‰": "xian",
        "è‹å·": "suzhou",
        "å¤©æ´¥": "tianjin",
        "é•¿æ²™": "changsha",
        "éƒ‘å·": "zhengzhou",
        "é’å²›": "qingdao",
        "å¤§è¿": "dalian",
        "å¦é—¨": "xiamen",
        "æ˜†æ˜": "kunming",
        "åˆè‚¥": "hefei",
        "ç¦å·": "fuzhou",
    }
    query = city_map.get(city, city)

    try:
        async with httpx.AsyncClient(timeout=15.0) as client:
            resp = await client.get(
                f"https://api.waqi.info/feed/{query}/",
                params={"token": "demo"},
            )
            data = resp.json()

        if data.get("status") != "ok":
            return f"æœªæ‰¾åˆ° {city} çš„ç©ºæ°”è´¨é‡æ•°æ®ã€‚"

        d = data["data"]
        aqi_val = d.get("aqi", "N/A")
        station = d.get("city", {}).get("name", city)
        time_str = d.get("time", {}).get("s", "")

        # AQI ç­‰çº§
        if isinstance(aqi_val, int):
            if aqi_val <= 50:
                level = "ä¼˜ ğŸŸ¢"
            elif aqi_val <= 100:
                level = "è‰¯ ğŸŸ¡"
            elif aqi_val <= 150:
                level = "è½»åº¦æ±¡æŸ“ ğŸŸ "
            elif aqi_val <= 200:
                level = "ä¸­åº¦æ±¡æŸ“ ğŸ”´"
            elif aqi_val <= 300:
                level = "é‡åº¦æ±¡æŸ“ ğŸŸ¤"
            else:
                level = "ä¸¥é‡æ±¡æŸ“ âš«"
        else:
            level = ""

        iaqi = d.get("iaqi", {})
        lines = [f"ğŸŒ {station}", f"AQI: {aqi_val} {level}"]
        if iaqi.get("pm25"):
            lines.append(f"PM2.5: {iaqi['pm25'].get('v', 'N/A')}")
        if iaqi.get("pm10"):
            lines.append(f"PM10: {iaqi['pm10'].get('v', 'N/A')}")
        if iaqi.get("o3"):
            lines.append(f"Oâ‚ƒ: {iaqi['o3'].get('v', 'N/A')}")
        if iaqi.get("t"):
            lines.append(f"æ¸©åº¦: {iaqi['t'].get('v', 'N/A')}â„ƒ")
        if iaqi.get("h"):
            lines.append(f"æ¹¿åº¦: {iaqi['h'].get('v', 'N/A')}%")
        if time_str:
            lines.append(f"æ›´æ–°: {time_str}")
        return "\n".join(lines)
    except Exception as e:
        return f"ç©ºæ°”è´¨é‡æŸ¥è¯¢å¤±è´¥: {e}"


HANDLERS: dict[str, object] = {
    "web_search": _tool_web_search,
    "weather": _tool_weather,
    "exchange_rate": _tool_exchange_rate,
    "stock_price": _tool_stock_price,
    "notion_search": _tool_notion_search,
    "notion_read": _tool_notion_read,
    "notion_create": _tool_notion_create,
    "read_url": _tool_read_url,
    "rss_read": _tool_rss_read,
    "translate": _tool_translate,
    "countdown": _tool_countdown,
    "trending": _tool_trending,
    "summarize": _tool_summarize,
    "sentiment": _tool_sentiment,
    "email_send": _tool_email_send,
    "qrcode": _tool_qrcode,
    "express_track": _tool_express_track,
    "flight_info": _tool_flight_info,
    "aqi": _tool_aqi,
}
